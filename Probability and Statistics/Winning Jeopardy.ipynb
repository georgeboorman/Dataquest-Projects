{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will be analysing a dataset of [Jeopardy](https://www.jeopardy.com/) questions to try and identify patterns in questions, which might offer a potential advance in winning the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41804 entries, 56 to 216746\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   Show Number  41804 non-null  int64         \n",
      " 1    Air Date    41804 non-null  datetime64[ns]\n",
      " 2    Round       41804 non-null  object        \n",
      " 3    Category    41804 non-null  object        \n",
      " 4    Value       41804 non-null  object        \n",
      " 5    Question    41804 non-null  object        \n",
      " 6    Answer      41803 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "\n",
    "jeopardy = pd.read_csv('JEOPARDY_CSV.csv')\n",
    "jeopardy[' Air Date'] = pd.to_datetime(jeopardy[' Air Date'])\n",
    "jeopardy = jeopardy[jeopardy[' Air Date'] > '2008-12-31']\n",
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['show_number', 'air_date', 'round', 'category', 'value', 'question',\n",
       "       'answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.rename(columns = {'Show Number':'show_number',' Air Date':'air_date', ' Round':'round', ' Category':'category', \n",
    "                           ' Value':'value', ' Question':'question', ' Answer':'answer'}, inplace=True)\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_number             int64\n",
       "air_date       datetime64[ns]\n",
       "round                  object\n",
       "category               object\n",
       "value                  object\n",
       "question               object\n",
       "answer                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56        England\n",
       "57    Miley Cyrus\n",
       "58       the skin\n",
       "59             48\n",
       "60      dribbling\n",
       "Name: answer, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['answer'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising Text\n",
    "\n",
    "Before we can commence our analysis we need to normalise some of the columns, specifically:\n",
    "\n",
    "-`question` and `answer`: remove punctuation, change all characters to lower case\n",
    "\n",
    "-`values`: remove dollar signs\n",
    "\n",
    "-`air_date`: convert to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def normalize_values(text):\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except Exception:\n",
    "        text = 0\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['answer'] = jeopardy['answer'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy[\"clean_question\"] = jeopardy[\"question\"].apply(normalize_text)\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"answer\"].apply(normalize_text)\n",
    "jeopardy[\"clean_value\"] = jeopardy[\"value\"].apply(normalize_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_number</th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5957</td>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>GEOGRAPHY \"E\"</td>\n",
       "      <td>$200</td>\n",
       "      <td>It's the largest kingdom in the United Kingdom</td>\n",
       "      <td>England</td>\n",
       "      <td>its the largest kingdom in the united kingdom</td>\n",
       "      <td>england</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5957</td>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>RADIO DISNEY</td>\n",
       "      <td>$200</td>\n",
       "      <td>\"Party In The U.S.A.\" is by this singer who al...</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>party in the usa is by this singer who also pl...</td>\n",
       "      <td>miley cyrus</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5957</td>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>PARTS OF PEACH</td>\n",
       "      <td>$200</td>\n",
       "      <td>If this part of a peach is downy or fuzzy, the...</td>\n",
       "      <td>the skin</td>\n",
       "      <td>if this part of a peach is downy or fuzzy the ...</td>\n",
       "      <td>the skin</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5957</td>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>BE FRUITFUL &amp; MULTIPLY</td>\n",
       "      <td>$200</td>\n",
       "      <td>4 x 12</td>\n",
       "      <td>48</td>\n",
       "      <td>4 x 12</td>\n",
       "      <td>48</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5957</td>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LET'S BOUNCE</td>\n",
       "      <td>$200</td>\n",
       "      <td>This verb for bouncing a basketball sounds lik...</td>\n",
       "      <td>dribbling</td>\n",
       "      <td>this verb for bouncing a basketball sounds lik...</td>\n",
       "      <td>dribbling</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    show_number   air_date      round                category value  \\\n",
       "56         5957 2010-07-06  Jeopardy!           GEOGRAPHY \"E\"  $200   \n",
       "57         5957 2010-07-06  Jeopardy!            RADIO DISNEY  $200   \n",
       "58         5957 2010-07-06  Jeopardy!          PARTS OF PEACH  $200   \n",
       "59         5957 2010-07-06  Jeopardy!  BE FRUITFUL & MULTIPLY  $200   \n",
       "60         5957 2010-07-06  Jeopardy!            LET'S BOUNCE  $200   \n",
       "\n",
       "                                             question       answer  \\\n",
       "56     It's the largest kingdom in the United Kingdom      England   \n",
       "57  \"Party In The U.S.A.\" is by this singer who al...  Miley Cyrus   \n",
       "58  If this part of a peach is downy or fuzzy, the...     the skin   \n",
       "59                                             4 x 12           48   \n",
       "60  This verb for bouncing a basketball sounds lik...    dribbling   \n",
       "\n",
       "                                       clean_question clean_answer  \\\n",
       "56      its the largest kingdom in the united kingdom      england   \n",
       "57  party in the usa is by this singer who also pl...  miley cyrus   \n",
       "58  if this part of a peach is downy or fuzzy the ...     the skin   \n",
       "59                                             4 x 12           48   \n",
       "60  this verb for bouncing a basketball sounds lik...    dribbling   \n",
       "\n",
       "    clean_value  \n",
       "56          200  \n",
       "57          200  \n",
       "58          200  \n",
       "59          200  \n",
       "60          200  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41804 entries, 56 to 216746\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   show_number     41804 non-null  int64         \n",
      " 1   air_date        41804 non-null  datetime64[ns]\n",
      " 2   round           41804 non-null  object        \n",
      " 3   category        41804 non-null  object        \n",
      " 4   value           41804 non-null  object        \n",
      " 5   question        41804 non-null  object        \n",
      " 6   answer          41804 non-null  object        \n",
      " 7   clean_question  41804 non-null  object        \n",
      " 8   clean_answer    41804 non-null  object        \n",
      " 9   clean_value     41804 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(7)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "import datetime as datetime\n",
    "jeopardy['air_date'] = pd.to_datetime(jeopardy['air_date'])\n",
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers in Questions\n",
    "\n",
    "In order to decide whether we should study past questions, study general knowledge, or not study at all, it would be helpful to understand:\n",
    "\n",
    "- How often the answer can be derived from the question\n",
    "- How often new questions are repeats of older questions\n",
    "\n",
    "For the former we can look at how many times words in the answer also occur in the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_in_question(row):\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()\n",
    "    match_count = 0\n",
    "    \n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    \n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    \n",
    "    for i in split_answer:\n",
    "        if i in split_question:\n",
    "            match_count += 1\n",
    "    \n",
    "    result = match_count/len(split_answer)\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06187277230419057"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['answer_in_question'] = jeopardy.apply(answer_in_question, axis=1)\n",
    "jeopardy['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, we can see that the answer can be deduced less than 6% of the time. Therefore this approach is unlikely to give us an advantage, and we should now look at how many times questions are repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7486609603581684"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "jeopardy.sort_values(by=['air_date'], inplace=True)\n",
    "\n",
    "for i, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(\" \")\n",
    "    #Looking at more complex words, using an arbitrary length filter of 6+ characters\n",
    "    split_question = [q for q in split_question if len(q) > 5]\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "jeopardy['question_overlap'] = question_overlap\n",
    "jeopardy['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a 75% overlap between terms in new questions and terms in old questions. Whilst we are only working with a dataset containing 10% of all jeopardy questions, and this only looks at individual words rather than phrases, it is likely to be more of a worthwhile strategy than studying for answers in questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Value vs High Value Questions\n",
    "\n",
    "If we segment the dataset into two categories we can then identify, through use of a Chi-Squared Test, which terms correspond to high value questions. \n",
    "\n",
    "To do this we can categorise data through the `value` column, with any row containing a value of less than 800 being considered low value, and anything above this classified as high value.\n",
    "\n",
    "We can then loop through the `terms_used` set to:\n",
    "\n",
    "- Find the number of low value questions the word occurs in\n",
    "- Find the number of high value questions the word occurs in\n",
    "- Find the percentage of questions the word occurs in\n",
    "- Based on the above percentage, find expected counts\n",
    "- Calculate the chi-squared value based on expected counts and the observed counts for high and low value questions\n",
    "\n",
    "Any words with the highest associated chi-squared values will suggest the largest differences in usage between high and low value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative to the high_value functon below\n",
    "#row['high_or_low'] = [lambda x: 1 for x in row['clean_value'] if i > 800, else 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_value(row):\n",
    "    value = 0\n",
    "    if row['clean_value'] > 800:\n",
    "        value = 1\n",
    "    return value\n",
    "\n",
    "jeopardy['high_value'] = jeopardy.apply(high_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41804, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['high_value'].value_counts()\n",
    "jeopardy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_or_low(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if word in row['clean_question'].split(\" \"):\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 6),\n",
       " (1, 5),\n",
       " (2, 4),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (3, 0),\n",
       " (1, 0),\n",
       " (5, 15),\n",
       " (0, 1),\n",
       " (2, 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = [choice(terms_used_list) for _ in range(10)]\n",
    "\n",
    "observed_expected = []\n",
    "\n",
    "for word in comparison_terms:\n",
    "    observed_expected.append(high_or_low(word))\n",
    "\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Chi-Square Test\n",
    "\n",
    "Now we have found the observed counts for a few words, we can compute the expected counts and the [chi-squared](https://en.wikipedia.org/wiki/Chi-squared_test) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=1.69721811617478, pvalue=0.19265218905181142),\n",
       " Power_divergenceResult(statistic=1.369540142184742, pvalue=0.24189090934291385),\n",
       " Power_divergenceResult(statistic=0.11371488228441806, pvalue=0.7359537954729485),\n",
       " Power_divergenceResult(statistic=0.6688889776038963, pvalue=0.41343922833074787),\n",
       " Power_divergenceResult(statistic=1.4950164130110415, pvalue=0.22143976330838874),\n",
       " Power_divergenceResult(statistic=4.485049239033124, pvalue=0.03419256146400087),\n",
       " Power_divergenceResult(statistic=1.4950164130110415, pvalue=0.22143976330838874),\n",
       " Power_divergenceResult(statistic=1.893771514307635, pvalue=0.16877714486249135),\n",
       " Power_divergenceResult(statistic=0.6688889776038963, pvalue=0.41343922833074787),\n",
       " Power_divergenceResult(statistic=2.990032826022083, pvalue=0.08377847019037524)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "high_value_count = jeopardy[jeopardy['high_value'] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy['high_value'] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "for i in observed_expected:\n",
    "    total = sum(i)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    \n",
    "    exp_high_value = total_prop * high_value_count\n",
    "    exp_low_value = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([i[0], i[1]])\n",
    "    expected = np.array([exp_high_value, exp_low_value])\n",
    "    \n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reacts'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_terms[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the chi-squared test results we can see only one term has statistically significant difference - 'reacts'. \n",
    "\n",
    "This is as far as we will go within project scope, but possible next steps for this could include:\n",
    "\n",
    "- Creating an alternative, more systematic approach to selecting complex words rather than taking an arbitrary character limit\n",
    "- Repeat the chi-squared test across a larger range of terms to try and identify which have larger differences\n",
    "- Analyse the categories column to calculate probabilities, helping people who are going on to the show to use ratios for their preparation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
